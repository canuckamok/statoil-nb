{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential model using Keras library\n",
    "\n",
    "Following instructions from here: https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n",
    "\n",
    "And using code from here: https://gist.github.com/fchollet/f35fbc80e066a49d65f1688a7e99f069\n",
    "\n",
    "The eventual fully connected layers will be based on this: https://www.kaggle.com/devm2024/transfer-learning-with-vgg-16-convnet-lb-0-1850/notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Create a new model\n",
    "\n",
    "create a new model that does not rely on Imagenet database (Since data is not similar to imagenet)\n",
    "\n",
    "#### Steps:\n",
    "1. import data\n",
    "2. separate training and validation sets\n",
    "3. get data and labels for both sets\n",
    "4. create simple model to start understanding data\n",
    "\n",
    "\n",
    "#### December 13 Steps:\n",
    "1. test linear images with CNN model\n",
    "2. test data augmentation at 5 different levels (Rotation, zoom, horizontal_flip, vertical_flip)\n",
    "3. create larger dataset by running data augmentation multiple times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense, Lambda, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras import applications\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import random\n",
    "from keras.utils import to_categorical\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#path = '/home/ubuntu/courses/deeplearning1/nbs/data/statoil/'\n",
    "path = '/Users/ilanrotenberg/projects/courses/deeplearning1/nbs/data/statoil/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define variables\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 75, 75\n",
    "\n",
    "top_model_weights_path = path + 'results/bottleneck_fc_model.h5'\n",
    "train_data_dir = path+ 'train/'\n",
    "validate_data_dir = path+ 'validate/'\n",
    "nb_train_samples = sum(os.path.isfile(os.path.join(train_data_dir + 'iceberg/', f)) for f in os.listdir(train_data_dir + 'iceberg/'))\n",
    "nb_train_samples += sum(os.path.isfile(os.path.join(train_data_dir + 'ship/', f)) for f in os.listdir(train_data_dir + 'ship/'))\n",
    "nb_validate_samples = sum(os.path.isfile(os.path.join(validate_data_dir + 'iceberg/', f)) for f in os.listdir(validate_data_dir + 'iceberg/'))\n",
    "nb_validate_samples += sum(os.path.isfile(os.path.join(validate_data_dir + 'ship/', f)) for f in os.listdir(validate_data_dir + 'ship/'))\n",
    "epochs = 50\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If data has already been split into train and validate sets - skip to the next markdown instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_path = path + '/train.json'\n",
    "test_path = path + '/test.json'\n",
    "train_batch = pd.read_json(train_path)\n",
    "test_batch = pd.read_json(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_batch[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validate_batch = train_batch.sample(frac=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validate_batch[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_train_batch = train_batch[~train_batch.index.isin(validate_batch.index)]\n",
    "new_train_batch[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validate_batch.to_json(path_or_buf = train_data_dir+'../validate.json')\n",
    "new_train_batch.to_json(path_or_buf = train_data_dir+'../train_new.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skip here if data has already been split into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_path = path + '/train_new.json'\n",
    "validate_path = path + '/validate.json'\n",
    "test_path = path + '/test.json'\n",
    "img_width, img_height = 75, 75\n",
    "train_batch = pd.read_json(train_path)\n",
    "validate_batch = pd.read_json(validate_path)\n",
    "test_batch = pd.read_json(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>band_1</th>\n",
       "      <th>band_2</th>\n",
       "      <th>id</th>\n",
       "      <th>inc_angle</th>\n",
       "      <th>is_iceberg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-27.878361, -27.15416, -28.668615, -29.537971...</td>\n",
       "      <td>[-27.154118, -29.537888, -31.0306, -32.190483,...</td>\n",
       "      <td>dfd5f913</td>\n",
       "      <td>43.9239</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-12.242375, -14.920305, -14.920363, -12.66633...</td>\n",
       "      <td>[-31.506321, -27.984554, -26.645678, -23.76760...</td>\n",
       "      <td>e25388fd</td>\n",
       "      <td>38.1562</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[-21.397552, -19.753859, -23.426783, -24.65221...</td>\n",
       "      <td>[-26.72291, -27.418192, -27.787899, -25.774536...</td>\n",
       "      <td>3aac67cd</td>\n",
       "      <td>44.6240</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>[-20.04884, -19.469616, -20.510244, -19.61095,...</td>\n",
       "      <td>[-29.742329, -26.374287, -25.490265, -25.49031...</td>\n",
       "      <td>66348d03</td>\n",
       "      <td>41.1342</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>[-22.34741, -22.156555, -25.308764, -24.530453...</td>\n",
       "      <td>[-24.782082, -24.047678, -24.782185, -27.45301...</td>\n",
       "      <td>3062fca8</td>\n",
       "      <td>39.9627</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 band_1  \\\n",
       "0     [-27.878361, -27.15416, -28.668615, -29.537971...   \n",
       "1     [-12.242375, -14.920305, -14.920363, -12.66633...   \n",
       "10    [-21.397552, -19.753859, -23.426783, -24.65221...   \n",
       "100   [-20.04884, -19.469616, -20.510244, -19.61095,...   \n",
       "1001  [-22.34741, -22.156555, -25.308764, -24.530453...   \n",
       "\n",
       "                                                 band_2        id  inc_angle  \\\n",
       "0     [-27.154118, -29.537888, -31.0306, -32.190483,...  dfd5f913    43.9239   \n",
       "1     [-31.506321, -27.984554, -26.645678, -23.76760...  e25388fd    38.1562   \n",
       "10    [-26.72291, -27.418192, -27.787899, -25.774536...  3aac67cd    44.6240   \n",
       "100   [-29.742329, -26.374287, -25.490265, -25.49031...  66348d03    41.1342   \n",
       "1001  [-24.782082, -24.047678, -24.782185, -27.45301...  3062fca8    39.9627   \n",
       "\n",
       "      is_iceberg  \n",
       "0              0  \n",
       "1              0  \n",
       "10             1  \n",
       "100            0  \n",
       "1001           1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_batch[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_batch.inc_angle = train_batch.inc_angle.apply(lambda x:np.nan if x =='na' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validate_batch.inc_angle = validate_batch.inc_angle.apply(lambda x:np.nan if x =='na' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_json(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_batch[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validate_batch[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def db_to_linear(band):\n",
    "    return np.power(10,np.array(band)/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_batch_band_1_lin = db_to_linear(train_band_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-f1ca2b29713f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_band_1_lin\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"jet\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "fig = plt.imshow(train_band_1_lin[3], cmap=\"jet\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_band_1 = np.array([np.array(band).astype('float32').reshape(img_width,img_height) for band in train_batch.band_1])\n",
    "train_band_2 = np.array([np.array(band).astype('float32').reshape(img_width,img_height) for band in train_batch.band_2])\n",
    "\n",
    "validate_band_1 = np.array([np.array(band).astype('float32').reshape(img_width,img_height) for band in validate_batch.band_1])\n",
    "validate_band_2 = np.array([np.array(band).astype('float32').reshape(img_width,img_height) for band in validate_batch.band_2])\n",
    "\n",
    "test_band_1 = np.array([np.array(band).astype('float32').reshape(img_width,img_height) for band in test_batch.band_1])\n",
    "test_band_2 = np.array([np.array(band).astype('float32').reshape(img_width,img_height) for band in test_batch.band_2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_band_1_lin = db_to_linear(train_band_1)\n",
    "train_band_2_lin = db_to_linear(train_band_2)\n",
    "\n",
    "validate_band_1_lin = db_to_linear(validate_band_1)\n",
    "validate_band_2_lin = db_to_linear(validate_band_2)\n",
    "\n",
    "test_band_1_lin = db_to_linear(test_band_1_lin)\n",
    "test_band_2_lin = db_to_linear(test_band_2_lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_band_3_lin = (train_band_1_lin +train_band_2_lin)/2\n",
    "validate_band_3_lin = (validate_band_1_lin+validate_band_2_lin)/2\n",
    "test_band_3_lin = (test_band_1_lin+test_band_2_lin)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "train_band_3 = (train_band_1+train_band_2)/2\n",
    "validate_band_3 = (validate_band_1+validate_band_2)/2\n",
    "test_band_3 = (test_band_1+test_band_2)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.concatenate([train_band_1[:,:,:,np.newaxis],\n",
    "                         train_band_2[:,:,:,np.newaxis],\n",
    "                         train_band_3[:,:,:,np.newaxis]],axis=-1)\n",
    "X_validate = np.concatenate([validate_band_1[:,:,:,np.newaxis],\n",
    "                            validate_band_2[:,:,:,np.newaxis],\n",
    "                            validate_band_3[:,:,:,np.newaxis]], axis=-1)\n",
    "X_test = np.concatenate([test_band_1[:,:,:,np.newaxis],\n",
    "                        test_band_2[:,:,:,np.newaxis],\n",
    "                        test_band_3[:,:,:,np.newaxis]], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_lin = np.concatenate([train_band_1_lin[:,:,:,np.newaxis],\n",
    "                         train_band_2_lin[:,:,:,np.newaxis],\n",
    "                         train_band_3_lin[:,:,:,np.newaxis]],axis=-1)\n",
    "X_validate_lin = np.concatenate([validate_band_1_lin[:,:,:,np.newaxis],\n",
    "                            validate_band_2_lin[:,:,:,np.newaxis],\n",
    "                            validate_band_3_lin[:,:,:,np.newaxis]], axis=-1)\n",
    "X_test_lin = np.concatenate([test_band_1_lin[:,:,:,np.newaxis],\n",
    "                        test_band_2_lin[:,:,:,np.newaxis],\n",
    "                        test_band_3_lin[:,:,:,np.newaxis]], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = np.array([np.array(iceberg).astype('uint8') for iceberg in train_batch.is_iceberg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_validate = np.array([np.array(iceberg).astype('uint8') for iceberg in validate_batch.is_iceberg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def onehot(x):\n",
    "    return to_categorical(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = onehot(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(481, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_validate = onehot(y_validate)\n",
    "y_validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_validate[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.moveaxis(X_train,3,1)\n",
    "X_validate = np.moveaxis(X_validate,3,1)\n",
    "X_test = np.moveaxis(X_test,3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(481, 3, 75, 75)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_trainx = X_train.mean().astype(np.float32)\n",
    "std_trainx = X_train.std().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def norm_input(x): return ((x-mean_trainx)/std_trainx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_linear_model():\n",
    "    model = Sequential([\n",
    "        Lambda(norm_input, input_shape = (3,img_height,img_width)),\n",
    "        Flatten(),\n",
    "        Dense(2, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer = 'Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm = get_linear_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen_lin = ImageDataGenerator(data_format='channels_first')\n",
    "batches_lin = gen_lin.flow(X_train_lin, y_train, batch_size=32, shuffle = True)\n",
    "validation_batches_lin = gen_lin.flow(X_validate_lin, y_validate, batch_size=32, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm.fit_generator(batches, batches.n/64, epochs = 1, \n",
    "                validation_data = validation_batches, validation_steps = validation_batches.n/64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm.optimizer.lr=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm.fit_generator(batches, batches.n/64, epochs = 1, \n",
    "                validation_data = validation_batches, validation_steps = validation_batches.n/64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm.optimizer.lr=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm.fit_generator(batches, batches.n/64, epochs = 20, \n",
    "                validation_data = validation_batches, validation_steps = validation_batches.n/64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Connected model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_fc_model():\n",
    "    model = Sequential([\n",
    "        Lambda(norm_input, input_shape = (3,img_height,img_width)),\n",
    "        Flatten(),\n",
    "        Dense(512, activation ='softmax'),\n",
    "        Dense(2, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer = 'Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc = get_fc_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc.fit_generator(batches, batches.n/64, epochs = 1, \n",
    "                validation_data = validation_batches, validation_steps = validation_batches.n/64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc.optimizer.lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc.fit_generator(batches, batches.n/64, epochs = 1, \n",
    "                validation_data = validation_batches, validation_steps = validation_batches.n/64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc.optimizer.lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc.fit_generator(batches, batches.n/64, epochs = 20, \n",
    "                validation_data = validation_batches, validation_steps = validation_batches.n/64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution model - same as below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cnn_model():\n",
    "    model = Sequential([\n",
    "        Lambda(norm_input, input_shape = (3,75,75)),\n",
    "        Conv2D(32, (3,3) ,activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Conv2D(32, (3,3),activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Conv2D(64, (3,3),activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Conv2D(64, (3,3),activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Conv2D(128, (3,3),activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Conv2D(128, (3,3),activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        BatchNormalization(),\n",
    "        Dense(512, activation ='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dense(2, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer = 'Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm = get_cnn_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm.fit_generator(batches, batches.n/64, epochs = 1, \n",
    "                validation_data = validation_batches, validation_steps = validation_batches.n/64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm.optimizer.lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm.fit_generator(batches, batches.n/64, epochs = 1, \n",
    "                validation_data = validation_batches, validation_steps = validation_batches.n/64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm.optimizer.lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm.fit_generator(batches, batches.n/64, epochs = 10, \n",
    "                validation_data = validation_batches, validation_steps = validation_batches.n/64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen = ImageDataGenerator(data_format='channels_first',\n",
    "                        rotation_range = 90.,\n",
    "                        horizontal_flip = True,\n",
    "                        vertical_flip = True)\n",
    "batches = gen.flow(X_train, y_train, batch_size=64, shuffle = True)\n",
    "validation_batches = gen.flow(X_validate, y_validate, batch_size=64, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm.fit_generator(batches, batches.n/64, epochs = 1, \n",
    "                validation_data = validation_batches, validation_steps = validation_batches.n/64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm.optimizer.lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm.fit_generator(batches, batches.n/64, epochs = 1, \n",
    "                validation_data = validation_batches, validation_steps = validation_batches.n/64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm.optimizer.lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm.fit_generator(batches, batches.n/64, epochs = 20, \n",
    "                validation_data = validation_batches, validation_steps = validation_batches.n/64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution model\n",
    "\n",
    "#### Tested with dropout but results were not great - worth trying varying amounts of dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cnn_dropout_model():\n",
    "    model = Sequential([\n",
    "        Lambda(norm_input, input_shape = (3,75,75)),\n",
    "        Conv2D(32, (3,3) ,activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Conv2D(32, (3,3),activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Conv2D(64, (3,3),activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Conv2D(64, (3,3),activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Conv2D(128, (3,3),activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Conv2D(128, (3,3),activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        BatchNormalization(),\n",
    "        Dense(512, activation ='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dense(2, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer = 'Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dn = get_cnn_dropout_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. test linear vs log models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    gen = ImageDataGenerator()\n",
    "    if i == 0:\n",
    "        batches = gen.flow(X_train, y_train, batch_size=64, shuffle = True)\n",
    "        validation_batches = gen.flow(X_validate, y_validate, batch_size=64, shuffle = True)\n",
    "    else:\n",
    "        batches = gen.flow(X_train_lin, y_train, batch_size=64, shuffle = True)\n",
    "        validation_batches = gen.flow(X_validate_lin, y_validate, batch_size=64, shuffle = True)\n",
    "    dn.fit_generator(batches, batches.n/64, epochs = 1, \n",
    "                validation_data = validation_batches, validation_steps = validation_batches.n/64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. test range of data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rotation is 60.0%'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 1\n",
    "'rotation is '+  str(20.+((i+1)*20)) + '%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    gen = ImageDataGenerator(rotation_range = 20.+(i*20))\n",
    "    'max rotation is: ' + str(20.+(i*20)) + ' degrees'\n",
    "    batches = gen.flow(X_train, y_train, batch_size=64, shuffle = True)\n",
    "    validation_batches = gen.flow(X_validate, y_validate, batch_size=64, shuffle = True)\n",
    "    dn.fit_generator(batches, batches.n/64, epochs = 1, \n",
    "                validation_data = validation_batches, validation_steps = validation_batches.n/64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    gen = ImageDataGenerator(zoom_range = (i*0.05))\n",
    "    'zoom is: +/-' + str((i*0.05)) + '%'\n",
    "    batches = gen.flow(X_train, y_train, batch_size=64, shuffle = True)\n",
    "    validation_batches = gen.flow(X_validate, y_validate, batch_size=64, shuffle = True)\n",
    "    dn.fit_generator(batches, batches.n/64, epochs = 1, \n",
    "                validation_data = validation_batches, validation_steps = validation_batches.n/64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. increase size of dataset for training\n",
    "\n",
    "Using fit instead of fit_generator now so I need to get the features of the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_feat = dn.predict_generator(validation_batches, validation_batches.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aug_feat = dn.predict_generator(batches, batches.n*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aug_labels = ([y_train]*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dn.fit(aug_feat, aug_labels, batch_size = 64, epochs = 1, validation_data = (val_feat, y_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NB: Run model in such a way to save weights to make the following ensembling go faster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Skip to ensemble model, these calculations are no longer needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dn.fit_generator(batches, batches.n/64, epochs = 1, \n",
    "                validation_data = validation_batches, validation_steps = validation_batches.n/64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dn.optimizer.lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dn.fit_generator(batches, batches.n/64, epochs = 5, \n",
    "                validation_data = validation_batches, validation_steps = validation_batches.n/64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dn.optimizer.lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dn.fit_generator(batches, batches.n/64, epochs = 15, \n",
    "                validation_data = validation_batches, validation_steps = validation_batches.n/64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble model\n",
    "\n",
    "Todo: use learnings from previous section to update the ensemble model to generate better predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ensemble() :\n",
    "    model = get_cnn_dropout_model()\n",
    "    model.fit_generator(batches, batches.n/64, epochs = 1, verbose = 0, \n",
    "                validation_data = validation_batches, validation_steps = validation_batches.n/64)\n",
    "    model.optimizer.lr = 0.1\n",
    "    model.fit_generator(batches, batches.n/64, epochs = 4,  verbose = 0, \n",
    "                validation_data = validation_batches, validation_steps = validation_batches.n/64)\n",
    "    model.optimizer.lr = 0.01\n",
    "    model.fit_generator(batches, batches.n/64, epochs = 12,  verbose = 0, \n",
    "                validation_data = validation_batches, validation_steps = validation_batches.n/64)\n",
    "    model.optimizer.lr = 0.001\n",
    "    model.fit_generator(batches, batches.n/64, epochs = 16,  verbose = 1, \n",
    "                validation_data = validation_batches, validation_steps = validation_batches.n/64)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/layers/core.py:630: UserWarning: `output_shape` argument not specified for layer lambda_2 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 3, 75, 75)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "18/17 [===============================] - 4s 200ms/step - loss: 0.3331 - acc: 0.8597 - val_loss: 0.9814 - val_acc: 0.6237\n",
      "Epoch 2/16\n",
      "18/17 [===============================] - 4s 207ms/step - loss: 0.2953 - acc: 0.8657 - val_loss: 1.6420 - val_acc: 0.5426\n",
      "Epoch 3/16\n",
      "18/17 [===============================] - 3s 191ms/step - loss: 0.3068 - acc: 0.8713 - val_loss: 1.1100 - val_acc: 0.6362\n",
      "Epoch 4/16\n",
      "18/17 [===============================] - 4s 209ms/step - loss: 0.2822 - acc: 0.8800 - val_loss: 1.4465 - val_acc: 0.5842\n",
      "Epoch 5/16\n",
      "18/17 [===============================] - 4s 230ms/step - loss: 0.2991 - acc: 0.8657 - val_loss: 0.7199 - val_acc: 0.6819\n",
      "Epoch 6/16\n",
      "18/17 [===============================] - 4s 224ms/step - loss: 0.3183 - acc: 0.8688 - val_loss: 0.7197 - val_acc: 0.6778\n",
      "Epoch 7/16\n",
      "18/17 [===============================] - 4s 196ms/step - loss: 0.2887 - acc: 0.8745 - val_loss: 0.5286 - val_acc: 0.7921\n",
      "Epoch 8/16\n",
      "18/17 [===============================] - 3s 186ms/step - loss: 0.2794 - acc: 0.8771 - val_loss: 2.0063 - val_acc: 0.5364\n",
      "Epoch 9/16\n",
      "18/17 [===============================] - 3s 192ms/step - loss: 0.3161 - acc: 0.8648 - val_loss: 1.0441 - val_acc: 0.6861\n",
      "Epoch 10/16\n",
      "18/17 [===============================] - 4s 208ms/step - loss: 0.2821 - acc: 0.8763 - val_loss: 0.3312 - val_acc: 0.8441\n",
      "Epoch 11/16\n",
      "18/17 [===============================] - 3s 191ms/step - loss: 0.2607 - acc: 0.8811 - val_loss: 0.7666 - val_acc: 0.7193\n",
      "Epoch 12/16\n",
      "18/17 [===============================] - 4s 197ms/step - loss: 0.2839 - acc: 0.8774 - val_loss: 0.7970 - val_acc: 0.7360\n",
      "Epoch 13/16\n",
      "18/17 [===============================] - 3s 185ms/step - loss: 0.2493 - acc: 0.8951 - val_loss: 0.3271 - val_acc: 0.8545\n",
      "Epoch 14/16\n",
      "18/17 [===============================] - 3s 191ms/step - loss: 0.2824 - acc: 0.8742 - val_loss: 0.3636 - val_acc: 0.8607\n",
      "Epoch 15/16\n",
      "18/17 [===============================] - 4s 219ms/step - loss: 0.2657 - acc: 0.8867 - val_loss: 0.4640 - val_acc: 0.8025\n",
      "Epoch 16/16\n",
      "18/17 [===============================] - 4s 202ms/step - loss: 0.2617 - acc: 0.8866 - val_loss: 0.3086 - val_acc: 0.8649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/layers/core.py:630: UserWarning: `output_shape` argument not specified for layer lambda_3 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 3, 75, 75)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "18/17 [===============================] - 4s 201ms/step - loss: 0.3213 - acc: 0.8658 - val_loss: 2.1599 - val_acc: 0.5426\n",
      "Epoch 2/16\n",
      "18/17 [===============================] - 4s 196ms/step - loss: 0.2929 - acc: 0.8678 - val_loss: 0.8075 - val_acc: 0.6632\n",
      "Epoch 3/16\n",
      "18/17 [===============================] - 4s 196ms/step - loss: 0.2842 - acc: 0.8856 - val_loss: 1.4938 - val_acc: 0.5863\n",
      "Epoch 4/16\n",
      "18/17 [===============================] - 3s 190ms/step - loss: 0.2903 - acc: 0.8703 - val_loss: 1.1837 - val_acc: 0.6507\n",
      "Epoch 5/16\n",
      "18/17 [===============================] - 4s 197ms/step - loss: 0.2872 - acc: 0.8750 - val_loss: 0.3966 - val_acc: 0.8420\n",
      "Epoch 6/16\n",
      "18/17 [===============================] - 3s 191ms/step - loss: 0.2822 - acc: 0.8691 - val_loss: 0.8305 - val_acc: 0.6819\n",
      "Epoch 7/16\n",
      "18/17 [===============================] - 3s 192ms/step - loss: 0.2792 - acc: 0.8852 - val_loss: 0.4297 - val_acc: 0.7921\n",
      "Epoch 8/16\n",
      "18/17 [===============================] - 4s 196ms/step - loss: 0.2671 - acc: 0.8783 - val_loss: 0.5668 - val_acc: 0.7484\n",
      "Epoch 9/16\n",
      "18/17 [===============================] - 3s 191ms/step - loss: 0.2402 - acc: 0.9042 - val_loss: 0.3946 - val_acc: 0.8462\n",
      "Epoch 10/16\n",
      "18/17 [===============================] - 4s 197ms/step - loss: 0.3079 - acc: 0.8629 - val_loss: 0.3241 - val_acc: 0.8607\n",
      "Epoch 11/16\n",
      "18/17 [===============================] - 3s 186ms/step - loss: 0.3442 - acc: 0.8507 - val_loss: 0.7592 - val_acc: 0.7048\n",
      "Epoch 12/16\n",
      "18/17 [===============================] - 3s 191ms/step - loss: 0.2846 - acc: 0.8772 - val_loss: 0.4399 - val_acc: 0.8358\n",
      "Epoch 13/16\n",
      "18/17 [===============================] - 4s 202ms/step - loss: 0.2571 - acc: 0.8890 - val_loss: 0.2867 - val_acc: 0.8794\n",
      "Epoch 14/16\n",
      "18/17 [===============================] - 4s 208ms/step - loss: 0.2867 - acc: 0.8690 - val_loss: 0.3275 - val_acc: 0.8669\n",
      "Epoch 15/16\n",
      "18/17 [===============================] - 3s 190ms/step - loss: 0.2958 - acc: 0.8716 - val_loss: 0.3550 - val_acc: 0.8482\n",
      "Epoch 16/16\n",
      "18/17 [===============================] - 3s 191ms/step - loss: 0.3010 - acc: 0.8737 - val_loss: 0.3636 - val_acc: 0.8462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/layers/core.py:630: UserWarning: `output_shape` argument not specified for layer lambda_4 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 3, 75, 75)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "18/17 [===============================] - 4s 203ms/step - loss: 0.2954 - acc: 0.8676 - val_loss: 0.6361 - val_acc: 0.7235\n",
      "Epoch 2/16\n",
      "18/17 [===============================] - 3s 192ms/step - loss: 0.3069 - acc: 0.8631 - val_loss: 1.1442 - val_acc: 0.6029\n",
      "Epoch 3/16\n",
      "18/17 [===============================] - 4s 198ms/step - loss: 0.3108 - acc: 0.8604 - val_loss: 0.6989 - val_acc: 0.7110\n",
      "Epoch 4/16\n",
      "18/17 [===============================] - 4s 202ms/step - loss: 0.3054 - acc: 0.8645 - val_loss: 0.9703 - val_acc: 0.6528\n",
      "Epoch 5/16\n",
      "18/17 [===============================] - 4s 196ms/step - loss: 0.3397 - acc: 0.8548 - val_loss: 0.8540 - val_acc: 0.6445\n",
      "Epoch 6/16\n",
      "18/17 [===============================] - 4s 204ms/step - loss: 0.2810 - acc: 0.8756 - val_loss: 0.4427 - val_acc: 0.7983\n",
      "Epoch 7/16\n",
      "18/17 [===============================] - 4s 203ms/step - loss: 0.3019 - acc: 0.8787 - val_loss: 0.3351 - val_acc: 0.8711\n",
      "Epoch 8/16\n",
      "18/17 [===============================] - 3s 191ms/step - loss: 0.3091 - acc: 0.8669 - val_loss: 0.4443 - val_acc: 0.7921\n",
      "Epoch 9/16\n",
      "18/17 [===============================] - 4s 202ms/step - loss: 0.2877 - acc: 0.8705 - val_loss: 0.9243 - val_acc: 0.6757\n",
      "Epoch 10/16\n",
      "18/17 [===============================] - 3s 191ms/step - loss: 0.2873 - acc: 0.8796 - val_loss: 0.4597 - val_acc: 0.8212\n",
      "Epoch 11/16\n",
      "18/17 [===============================] - 4s 196ms/step - loss: 0.2920 - acc: 0.8591 - val_loss: 0.3189 - val_acc: 0.8690\n",
      "Epoch 12/16\n",
      "18/17 [===============================] - 3s 191ms/step - loss: 0.2868 - acc: 0.8846 - val_loss: 0.4781 - val_acc: 0.7796\n",
      "Epoch 13/16\n",
      "18/17 [===============================] - 4s 233ms/step - loss: 0.2646 - acc: 0.8778 - val_loss: 0.2899 - val_acc: 0.8711\n",
      "Epoch 14/16\n",
      "18/17 [===============================] - 3s 191ms/step - loss: 0.2995 - acc: 0.8760 - val_loss: 0.3168 - val_acc: 0.8524\n",
      "Epoch 15/16\n",
      "18/17 [===============================] - 4s 197ms/step - loss: 0.2788 - acc: 0.8741 - val_loss: 0.6509 - val_acc: 0.7089\n",
      "Epoch 16/16\n",
      "18/17 [===============================] - 4s 197ms/step - loss: 0.2581 - acc: 0.8923 - val_loss: 0.2886 - val_acc: 0.8669\n"
     ]
    }
   ],
   "source": [
    "models = [get_ensemble() for i in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_path = path+'models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i,m in enumerate(models):\n",
    "    m.save_weights(model_path + 'cnn_statoil_' + str(i) + '.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "481/481 [==============================] - 0s 983us/step\n",
      "481/481 [==============================] - 0s 784us/step\n",
      "481/481 [==============================] - 0s 716us/step\n"
     ]
    }
   ],
   "source": [
    "evals = np.array([m.evaluate(X_validate, y_validate, batch_size=256) for m in models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.31128727,  0.86555786])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evals.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_preds = np.stack([m.predict(X_test, batch_size = 256) for m in models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 8424, 2)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_preds = all_preds.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9.87748384e-01,   1.22515941e-02],\n",
       "       [  2.95811206e-01,   7.04188824e-01],\n",
       "       [  9.99622107e-01,   3.77853168e-04],\n",
       "       [  1.49961412e-02,   9.85003889e-01],\n",
       "       [  1.97269008e-01,   8.02730978e-01]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.22515941e-02,   7.04188824e-01,   3.77853168e-04, ...,\n",
       "         8.63429084e-02,   9.87904549e-01,   9.51587975e-01], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_preds[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.31043216,  0.86070687],\n",
       "       [ 0.3627157 ,  0.84823284],\n",
       "       [ 0.26071394,  0.88773388]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_validate[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>band_1</th>\n",
       "      <th>band_2</th>\n",
       "      <th>id</th>\n",
       "      <th>inc_angle</th>\n",
       "      <th>is_iceberg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[-21.397552, -19.753859, -23.426783, -24.65221...</td>\n",
       "      <td>[-26.72291, -27.418192, -27.787899, -25.774536...</td>\n",
       "      <td>3aac67cd</td>\n",
       "      <td>44.6240</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>[-25.098461, -25.098461, -24.320147, -21.05014...</td>\n",
       "      <td>[-29.62639, -29.62639, -28.757122, -29.180954,...</td>\n",
       "      <td>b7519a52</td>\n",
       "      <td>42.5590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>[-21.582905, -15.472338, -16.417433, -16.72227...</td>\n",
       "      <td>[-25.104729, -24.326412, -28.763432, -32.92899...</td>\n",
       "      <td>204941f0</td>\n",
       "      <td>42.4664</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>[-13.271194, -12.898959, -14.867657, -16.54327...</td>\n",
       "      <td>[-22.941357, -23.540695, -24.41008, -24.879778...</td>\n",
       "      <td>f9209504</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>[-13.523142, -10.304675, -11.433078, -9.585804...</td>\n",
       "      <td>[-21.386665, -21.076504, -20.776958, -22.21468...</td>\n",
       "      <td>204afe46</td>\n",
       "      <td>32.8010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 band_1  \\\n",
       "10    [-21.397552, -19.753859, -23.426783, -24.65221...   \n",
       "1003  [-25.098461, -25.098461, -24.320147, -21.05014...   \n",
       "1006  [-21.582905, -15.472338, -16.417433, -16.72227...   \n",
       "101   [-13.271194, -12.898959, -14.867657, -16.54327...   \n",
       "1012  [-13.523142, -10.304675, -11.433078, -9.585804...   \n",
       "\n",
       "                                                 band_2        id  inc_angle  \\\n",
       "10    [-26.72291, -27.418192, -27.787899, -25.774536...  3aac67cd    44.6240   \n",
       "1003  [-29.62639, -29.62639, -28.757122, -29.180954,...  b7519a52    42.5590   \n",
       "1006  [-25.104729, -24.326412, -28.763432, -32.92899...  204941f0    42.4664   \n",
       "101   [-22.941357, -23.540695, -24.41008, -24.879778...  f9209504        NaN   \n",
       "1012  [-21.386665, -21.076504, -20.776958, -22.21468...  204afe46    32.8010   \n",
       "\n",
       "      is_iceberg  \n",
       "10             1  \n",
       "1003           1  \n",
       "1006           0  \n",
       "101            0  \n",
       "1012           1  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_batch[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['id']=test_batch['id']\n",
    "submission['is_iceberg']=avg_preds[:,1].clip(0.025, 0.975)\n",
    "submission.to_csv(path+'submission17124.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.025     ,  0.70418882,  0.025     , ...,  0.08634291,\n",
       "        0.97500002,  0.95158798], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_preds[:,1].clip(0.025, 0.975)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/courses/deeplearning1/nbs/statoil-nb'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "import os, sys\n",
    "submit_path = os.getcwd()\n",
    "submit_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submit_path = submit_path+'/../data/statoil'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='/home/ubuntu/courses/deeplearning1/nbs/statoil-nb/../data/statoil/submission17124.csv' target='_blank'>/home/ubuntu/courses/deeplearning1/nbs/statoil-nb/../data/statoil/submission17124.csv</a><br>"
      ],
      "text/plain": [
       "/home/ubuntu/courses/deeplearning1/nbs/data/statoil/submission17124.csv"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FileLink(submit_path+'/submission17124.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
