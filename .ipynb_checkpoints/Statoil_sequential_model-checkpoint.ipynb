{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential model using Keras library\n",
    "\n",
    "Following instructions from here: https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n",
    "\n",
    "And using code from here: https://gist.github.com/fchollet/f35fbc80e066a49d65f1688a7e99f069\n",
    "\n",
    "The eventual fully connected layers will be based on this: https://www.kaggle.com/devm2024/transfer-learning-with-vgg-16-convnet-lb-0-1850/notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Create a new model\n",
    "\n",
    "create a new model that does not rely on Imagenet database (Since data is not similar to imagenet)\n",
    "\n",
    "#### Steps:\n",
    "1. import data\n",
    "2. separate training and validation sets\n",
    "3. get data and labels for both sets\n",
    "4. create simple model to start understanding data\n",
    "\n",
    "\n",
    "#### December 13 Steps:\n",
    "1. test linear images with CNN model\n",
    "2. test data augmentation at 5 different levels (Rotation, zoom, horizontal_flip, vertical_flip)\n",
    "3. create larger dataset by running data augmentation multiple times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense, Lambda, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras import applications\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import random\n",
    "from keras.utils import to_categorical\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '/home/ubuntu/courses/deeplearning1/nbs/data/statoil/'\n",
    "#path = '/Users/ilanrotenberg/projects/courses/deeplearning1/nbs/data/statoil/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define variables\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 75, 75\n",
    "\n",
    "top_model_weights_path = path + 'results/bottleneck_fc_model.h5'\n",
    "train_data_dir = path+ 'train/'\n",
    "validate_data_dir = path+ 'validate/'\n",
    "nb_train_samples = sum(os.path.isfile(os.path.join(train_data_dir + 'iceberg/', f)) for f in os.listdir(train_data_dir + 'iceberg/'))\n",
    "nb_train_samples += sum(os.path.isfile(os.path.join(train_data_dir + 'ship/', f)) for f in os.listdir(train_data_dir + 'ship/'))\n",
    "nb_validate_samples = sum(os.path.isfile(os.path.join(validate_data_dir + 'iceberg/', f)) for f in os.listdir(validate_data_dir + 'iceberg/'))\n",
    "nb_validate_samples += sum(os.path.isfile(os.path.join(validate_data_dir + 'ship/', f)) for f in os.listdir(validate_data_dir + 'ship/'))\n",
    "epochs = 50\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If data has already been split into train and validate sets - skip to the next markdown instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_path = path + '/train.json'\n",
    "test_path = path + '/test.json'\n",
    "train_batch = pd.read_json(train_path)\n",
    "test_batch = pd.read_json(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_batch[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validate_batch = train_batch.sample(frac=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validate_batch[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_train_batch = train_batch[~train_batch.index.isin(validate_batch.index)]\n",
    "new_train_batch[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validate_batch.to_json(path_or_buf = train_data_dir+'../validate.json')\n",
    "new_train_batch.to_json(path_or_buf = train_data_dir+'../train_new.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skip here if data has already been split into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_path = path + '/train_new.json'\n",
    "validate_path = path + '/validate.json'\n",
    "test_path = path + '/test.json'\n",
    "img_width, img_height = 75, 75\n",
    "train_batch = pd.read_json(train_path)\n",
    "validate_batch = pd.read_json(validate_path)\n",
    "test_batch = pd.read_json(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>band_1</th>\n",
       "      <th>band_2</th>\n",
       "      <th>id</th>\n",
       "      <th>inc_angle</th>\n",
       "      <th>is_iceberg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-27.878361, -27.15416, -28.668615, -29.537971...</td>\n",
       "      <td>[-27.154118, -29.537888, -31.0306, -32.190483,...</td>\n",
       "      <td>dfd5f913</td>\n",
       "      <td>43.9239</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-12.242375, -14.920305, -14.920363, -12.66633...</td>\n",
       "      <td>[-31.506321, -27.984554, -26.645678, -23.76760...</td>\n",
       "      <td>e25388fd</td>\n",
       "      <td>38.1562</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[-21.397552, -19.753859, -23.426783, -24.65221...</td>\n",
       "      <td>[-26.72291, -27.418192, -27.787899, -25.774536...</td>\n",
       "      <td>3aac67cd</td>\n",
       "      <td>44.6240</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>[-20.04884, -19.469616, -20.510244, -19.61095,...</td>\n",
       "      <td>[-29.742329, -26.374287, -25.490265, -25.49031...</td>\n",
       "      <td>66348d03</td>\n",
       "      <td>41.1342</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>[-22.34741, -22.156555, -25.308764, -24.530453...</td>\n",
       "      <td>[-24.782082, -24.047678, -24.782185, -27.45301...</td>\n",
       "      <td>3062fca8</td>\n",
       "      <td>39.9627</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 band_1  \\\n",
       "0     [-27.878361, -27.15416, -28.668615, -29.537971...   \n",
       "1     [-12.242375, -14.920305, -14.920363, -12.66633...   \n",
       "10    [-21.397552, -19.753859, -23.426783, -24.65221...   \n",
       "100   [-20.04884, -19.469616, -20.510244, -19.61095,...   \n",
       "1001  [-22.34741, -22.156555, -25.308764, -24.530453...   \n",
       "\n",
       "                                                 band_2        id  inc_angle  \\\n",
       "0     [-27.154118, -29.537888, -31.0306, -32.190483,...  dfd5f913    43.9239   \n",
       "1     [-31.506321, -27.984554, -26.645678, -23.76760...  e25388fd    38.1562   \n",
       "10    [-26.72291, -27.418192, -27.787899, -25.774536...  3aac67cd    44.6240   \n",
       "100   [-29.742329, -26.374287, -25.490265, -25.49031...  66348d03    41.1342   \n",
       "1001  [-24.782082, -24.047678, -24.782185, -27.45301...  3062fca8    39.9627   \n",
       "\n",
       "      is_iceberg  \n",
       "0              0  \n",
       "1              0  \n",
       "10             1  \n",
       "100            0  \n",
       "1001           1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_batch[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_batch.inc_angle = train_batch.inc_angle.apply(lambda x:np.nan if x =='na' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validate_batch.inc_angle = validate_batch.inc_angle.apply(lambda x:np.nan if x =='na' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_json(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>band_1</th>\n",
       "      <th>band_2</th>\n",
       "      <th>id</th>\n",
       "      <th>inc_angle</th>\n",
       "      <th>is_iceberg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-27.878361, -27.15416, -28.668615, -29.537971...</td>\n",
       "      <td>[-27.154118, -29.537888, -31.0306, -32.190483,...</td>\n",
       "      <td>dfd5f913</td>\n",
       "      <td>43.9239</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-12.242375, -14.920305, -14.920363, -12.66633...</td>\n",
       "      <td>[-31.506321, -27.984554, -26.645678, -23.76760...</td>\n",
       "      <td>e25388fd</td>\n",
       "      <td>38.1562</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>[-20.04884, -19.469616, -20.510244, -19.61095,...</td>\n",
       "      <td>[-29.742329, -26.374287, -25.490265, -25.49031...</td>\n",
       "      <td>66348d03</td>\n",
       "      <td>41.1342</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>[-23.199345, -23.603487, -25.965549, -27.12546...</td>\n",
       "      <td>[-23.004148, -24.942425, -24.472878, -23.00437...</td>\n",
       "      <td>7052a617</td>\n",
       "      <td>33.8975</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>[-22.34741, -22.156555, -25.308764, -24.530453...</td>\n",
       "      <td>[-24.782082, -24.047678, -24.782185, -27.45301...</td>\n",
       "      <td>3062fca8</td>\n",
       "      <td>39.9627</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 band_1  \\\n",
       "0     [-27.878361, -27.15416, -28.668615, -29.537971...   \n",
       "1     [-12.242375, -14.920305, -14.920363, -12.66633...   \n",
       "100   [-20.04884, -19.469616, -20.510244, -19.61095,...   \n",
       "1000  [-23.199345, -23.603487, -25.965549, -27.12546...   \n",
       "1001  [-22.34741, -22.156555, -25.308764, -24.530453...   \n",
       "\n",
       "                                                 band_2        id  inc_angle  \\\n",
       "0     [-27.154118, -29.537888, -31.0306, -32.190483,...  dfd5f913    43.9239   \n",
       "1     [-31.506321, -27.984554, -26.645678, -23.76760...  e25388fd    38.1562   \n",
       "100   [-29.742329, -26.374287, -25.490265, -25.49031...  66348d03    41.1342   \n",
       "1000  [-23.004148, -24.942425, -24.472878, -23.00437...  7052a617    33.8975   \n",
       "1001  [-24.782082, -24.047678, -24.782185, -27.45301...  3062fca8    39.9627   \n",
       "\n",
       "      is_iceberg  \n",
       "0              0  \n",
       "1              0  \n",
       "100            0  \n",
       "1000           0  \n",
       "1001           1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_batch[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>band_1</th>\n",
       "      <th>band_2</th>\n",
       "      <th>id</th>\n",
       "      <th>inc_angle</th>\n",
       "      <th>is_iceberg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[-21.397552, -19.753859, -23.426783, -24.65221...</td>\n",
       "      <td>[-26.72291, -27.418192, -27.787899, -25.774536...</td>\n",
       "      <td>3aac67cd</td>\n",
       "      <td>44.6240</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>[-25.098461, -25.098461, -24.320147, -21.05014...</td>\n",
       "      <td>[-29.62639, -29.62639, -28.757122, -29.180954,...</td>\n",
       "      <td>b7519a52</td>\n",
       "      <td>42.5590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>[-21.582905, -15.472338, -16.417433, -16.72227...</td>\n",
       "      <td>[-25.104729, -24.326412, -28.763432, -32.92899...</td>\n",
       "      <td>204941f0</td>\n",
       "      <td>42.4664</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>[-13.271194, -12.898959, -14.867657, -16.54327...</td>\n",
       "      <td>[-22.941357, -23.540695, -24.41008, -24.879778...</td>\n",
       "      <td>f9209504</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>[-13.523142, -10.304675, -11.433078, -9.585804...</td>\n",
       "      <td>[-21.386665, -21.076504, -20.776958, -22.21468...</td>\n",
       "      <td>204afe46</td>\n",
       "      <td>32.8010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 band_1  \\\n",
       "10    [-21.397552, -19.753859, -23.426783, -24.65221...   \n",
       "1003  [-25.098461, -25.098461, -24.320147, -21.05014...   \n",
       "1006  [-21.582905, -15.472338, -16.417433, -16.72227...   \n",
       "101   [-13.271194, -12.898959, -14.867657, -16.54327...   \n",
       "1012  [-13.523142, -10.304675, -11.433078, -9.585804...   \n",
       "\n",
       "                                                 band_2        id  inc_angle  \\\n",
       "10    [-26.72291, -27.418192, -27.787899, -25.774536...  3aac67cd    44.6240   \n",
       "1003  [-29.62639, -29.62639, -28.757122, -29.180954,...  b7519a52    42.5590   \n",
       "1006  [-25.104729, -24.326412, -28.763432, -32.92899...  204941f0    42.4664   \n",
       "101   [-22.941357, -23.540695, -24.41008, -24.879778...  f9209504        NaN   \n",
       "1012  [-21.386665, -21.076504, -20.776958, -22.21468...  204afe46    32.8010   \n",
       "\n",
       "      is_iceberg  \n",
       "10             1  \n",
       "1003           1  \n",
       "1006           0  \n",
       "101            0  \n",
       "1012           1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_batch[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def db_to_linear(band):\n",
    "    return np.power(10,np.array(band)/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_band_1 = np.array([np.array(band).astype('float32').reshape(img_width,img_height) for band in train_batch.band_1])\n",
    "train_band_2 = np.array([np.array(band).astype('float32').reshape(img_width,img_height) for band in train_batch.band_2])\n",
    "\n",
    "validate_band_1 = np.array([np.array(band).astype('float32').reshape(img_width,img_height) for band in validate_batch.band_1])\n",
    "validate_band_2 = np.array([np.array(band).astype('float32').reshape(img_width,img_height) for band in validate_batch.band_2])\n",
    "\n",
    "test_band_1 = np.array([np.array(band).astype('float32').reshape(img_width,img_height) for band in test_batch.band_1])\n",
    "test_band_2 = np.array([np.array(band).astype('float32').reshape(img_width,img_height) for band in test_batch.band_2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_band_1_lin = db_to_linear(train_band_1)\n",
    "train_band_2_lin = db_to_linear(train_band_2)\n",
    "\n",
    "validate_band_1_lin = db_to_linear(validate_band_1)\n",
    "validate_band_2_lin = db_to_linear(validate_band_2)\n",
    "\n",
    "test_band_1_lin = db_to_linear(test_band_1)\n",
    "test_band_2_lin = db_to_linear(test_band_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f97e79faf10>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAC7CAYAAAB1qmWGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9639ad0750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1)\n",
    "plt.subplot(121).imshow(train_band_1_lin[3], cmap = 'jet')\n",
    "plt.subplot(122).imshow(train_band_1[3], cmap='jet')\n",
    "\n",
    "#fig = plt.imshow(train_band_1_lin[3], cmap = 'jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_band_3_lin = (train_band_1_lin +train_band_2_lin)/2\n",
    "validate_band_3_lin = (validate_band_1_lin+validate_band_2_lin)/2\n",
    "test_band_3_lin = (test_band_1_lin+test_band_2_lin)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "train_band_3 = (train_band_1+train_band_2)/2\n",
    "validate_band_3 = (validate_band_1+validate_band_2)/2\n",
    "test_band_3 = (test_band_1+test_band_2)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.concatenate([train_band_1[:,:,:,np.newaxis],\n",
    "                         train_band_2[:,:,:,np.newaxis],\n",
    "                         train_band_3[:,:,:,np.newaxis]],axis=-1)\n",
    "X_validate = np.concatenate([validate_band_1[:,:,:,np.newaxis],\n",
    "                            validate_band_2[:,:,:,np.newaxis],\n",
    "                            validate_band_3[:,:,:,np.newaxis]], axis=-1)\n",
    "X_test = np.concatenate([test_band_1[:,:,:,np.newaxis],\n",
    "                        test_band_2[:,:,:,np.newaxis],\n",
    "                        test_band_3[:,:,:,np.newaxis]], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_lin = np.concatenate([train_band_1_lin[:,:,:,np.newaxis],\n",
    "                         train_band_2_lin[:,:,:,np.newaxis],\n",
    "                         train_band_3_lin[:,:,:,np.newaxis]],axis=-1)\n",
    "X_validate_lin = np.concatenate([validate_band_1_lin[:,:,:,np.newaxis],\n",
    "                            validate_band_2_lin[:,:,:,np.newaxis],\n",
    "                            validate_band_3_lin[:,:,:,np.newaxis]], axis=-1)\n",
    "X_test_lin = np.concatenate([test_band_1_lin[:,:,:,np.newaxis],\n",
    "                        test_band_2_lin[:,:,:,np.newaxis],\n",
    "                        test_band_3_lin[:,:,:,np.newaxis]], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = np.array([np.array(iceberg).astype('uint8') for iceberg in train_batch.is_iceberg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1123,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_validate = np.array([np.array(iceberg).astype('uint8') for iceberg in validate_batch.is_iceberg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(481,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1123, 75, 75, 3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(481, 75, 75, 3)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def onehot(x):\n",
    "    return to_categorical(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = onehot(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(481, 2)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_validate = onehot(y_validate)\n",
    "y_validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_validate[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.moveaxis(X_train,3,1)\n",
    "X_validate = np.moveaxis(X_validate,3,1)\n",
    "X_test = np.moveaxis(X_test,3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_lin = np.moveaxis(X_train_lin,3,1)\n",
    "X_validate_lin = np.moveaxis(X_validate_lin,3,1)\n",
    "X_test_lin = np.moveaxis(X_test_lin,3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(481, 3, 75, 75)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_trainx = X_train.mean().astype(np.float32)\n",
    "std_trainx = X_train.std().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def norm_input(x): return ((x-mean_trainx)/std_trainx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_linear_model():\n",
    "    model = Sequential([\n",
    "        Lambda(norm_input, input_shape = (3,img_height,img_width)),\n",
    "        Flatten(),\n",
    "        Dense(2, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer = 'Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm = get_linear_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen_lin = ImageDataGenerator(data_format='channels_first')\n",
    "batches_lin = gen_lin.flow(X_train_lin, y_train, batch_size=32, shuffle = True)\n",
    "validation_batches_lin = gen_lin.flow(X_validate_lin, y_validate, batch_size=32, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm.fit_generator(batches, batches.n/64, epochs = 1, \n",
    "                validation_data = validation_batches, validation_steps = validation_batches.n/64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm.optimizer.lr=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm.fit_generator(batches, batches.n/64, epochs = 1, \n",
    "                validation_data = validation_batches, validation_steps = validation_batches.n/64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm.optimizer.lr=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm.fit_generator(batches, batches.n/64, epochs = 20, \n",
    "                validation_data = validation_batches, validation_steps = validation_batches.n/64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Connected model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_fc_model():\n",
    "    model = Sequential([\n",
    "        Lambda(norm_input, input_shape = (3,img_height,img_width)),\n",
    "        Flatten(),\n",
    "        Dense(512, activation ='softmax'),\n",
    "        Dense(2, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer = 'Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc = get_fc_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc.fit_generator(batches, batches.n/64, epochs = 1, \n",
    "                validation_data = validation_batches, validation_steps = validation_batches.n/64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc.optimizer.lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc.fit_generator(batches, batches.n/64, epochs = 1, \n",
    "                validation_data = validation_batches, validation_steps = validation_batches.n/64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc.optimizer.lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc.fit_generator(batches, batches.n/64, epochs = 20, \n",
    "                validation_data = validation_batches, validation_steps = validation_batches.n/64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution model - same as below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cnn_model():\n",
    "    model = Sequential([\n",
    "        Lambda(norm_input, input_shape = (3,75,75)),\n",
    "        Conv2D(32, (3,3) ,activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Conv2D(32, (3,3),activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Conv2D(64, (3,3),activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Conv2D(64, (3,3),activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Conv2D(128, (3,3),activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Conv2D(128, (3,3),activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        BatchNormalization(),\n",
    "        Dense(512, activation ='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dense(2, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer = 'Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm = get_cnn_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm.fit_generator(batches, batches.n/64, epochs = 1, \n",
    "                validation_data = validation_batches, validation_steps = validation_batches.n/64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm.optimizer.lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm.fit_generator(batches, batches.n/64, epochs = 1, \n",
    "                validation_data = validation_batches, validation_steps = validation_batches.n/64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm.optimizer.lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm.fit_generator(batches, batches.n/64, epochs = 10, \n",
    "                validation_data = validation_batches, validation_steps = validation_batches.n/64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen = ImageDataGenerator(data_format='channels_first',\n",
    "                        rotation_range = 90.,\n",
    "                        horizontal_flip = True,\n",
    "                        vertical_flip = True)\n",
    "batches = gen.flow(X_train, y_train, batch_size=64, shuffle = True)\n",
    "validation_batches = gen.flow(X_validate, y_validate, batch_size=64, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm.fit_generator(batches, batches.n/64, epochs = 1, \n",
    "                validation_data = validation_batches, validation_steps = validation_batches.n/64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm.optimizer.lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm.fit_generator(batches, batches.n/64, epochs = 1, \n",
    "                validation_data = validation_batches, validation_steps = validation_batches.n/64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm.optimizer.lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm.fit_generator(batches, batches.n/64, epochs = 20, \n",
    "                validation_data = validation_batches, validation_steps = validation_batches.n/64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution model\n",
    "\n",
    "#### Tested with 0.5 and 0.3 dropout in the fully connected but results were not great - worth trying varying amounts of dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cnn_dropout_model():\n",
    "    model = Sequential([\n",
    "        Lambda(norm_input, input_shape = (3,75,75)),\n",
    "        Conv2D(32, (3,3) ,activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Conv2D(32, (3,3),activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Conv2D(64, (3,3),activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Conv2D(64, (3,3),activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Conv2D(128, (3,3),activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Conv2D(128, (3,3),activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        BatchNormalization(),\n",
    "        Dense(512, activation ='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dense(2, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer = 'Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/layers/core.py:630: UserWarning: `output_shape` argument not specified for layer lambda_2 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 3, 75, 75)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    }
   ],
   "source": [
    "dn = get_cnn_dropout_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. test linear vs log models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "18/17 [===============================] - 4s 197ms/step - loss: 0.3245 - acc: 0.8543 - val_loss: 0.8362 - val_acc: 0.5821\n",
      "Epoch 2/3\n",
      "18/17 [===============================] - 3s 180ms/step - loss: 0.1942 - acc: 0.9233 - val_loss: 0.9268 - val_acc: 0.5301\n",
      "Epoch 3/3\n",
      "18/17 [===============================] - 3s 180ms/step - loss: 0.1234 - acc: 0.9559 - val_loss: 1.0826 - val_acc: 0.5052\n",
      "Epoch 1/3\n",
      "18/17 [===============================] - 3s 187ms/step - loss: 0.5453 - acc: 0.7333 - val_loss: 0.8502 - val_acc: 0.4948\n",
      "Epoch 2/3\n",
      "18/17 [===============================] - 3s 180ms/step - loss: 0.3939 - acc: 0.7927 - val_loss: 1.1014 - val_acc: 0.4990\n",
      "Epoch 3/3\n",
      "18/17 [===============================] - 3s 180ms/step - loss: 0.3487 - acc: 0.8347 - val_loss: 0.7572 - val_acc: 0.5052\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    gen = ImageDataGenerator()\n",
    "    if i == 0:\n",
    "        batches = gen.flow(X_train, y_train, batch_size=64, shuffle = True)\n",
    "        validation_batches = gen.flow(X_validate, y_validate, batch_size=64, shuffle = True)\n",
    "    else:\n",
    "        batches = gen.flow(X_train_lin, y_train, batch_size=64, shuffle = True)\n",
    "        validation_batches = gen.flow(X_validate_lin, y_validate, batch_size=64, shuffle = True)\n",
    "    dn.fit_generator(batches, batches.n/64, epochs = 3, \n",
    "                validation_data = validation_batches, validation_steps = validation_batches.n/64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the dB has higher accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. test range of data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen = ImageDataGenerator()\n",
    "validation_batches = gen.flow(X_validate, y_validate, batch_size = 128, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_model(batches):\n",
    "    model = Sequential([\n",
    "        Lambda(norm_input, input_shape = (3,75,75)),\n",
    "        Conv2D(32, (3,3) ,activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        #Dropout(0.1),\n",
    "        Conv2D(32, (3,3),activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Conv2D(64, (3,3),activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Dropout(0.1),\n",
    "        Conv2D(64, (3,3),activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Conv2D(128, (3,3),activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        #Dropout(0.1),\n",
    "        Conv2D(128, (3,3),activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        BatchNormalization(),\n",
    "        Dense(512, activation ='relu'),\n",
    "        BatchNormalization(),\n",
    "        #Dropout(0.1),\n",
    "        Dense(128, activation ='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dense(2, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer = 'Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.optimizer.lr = 0.00001\n",
    "    model.fit_generator(batches, batches.n/64, epochs = 10, verbose = 0,\n",
    "                       validation_data = validation_batches, validation_steps = validation_batches.n)\n",
    "    model.optimizer.lr = 0.1\n",
    "    model.fit_generator(batches, batches.n/64, epochs = 8, verbose = 0,\n",
    "                       validation_data = validation_batches, validation_steps = validation_batches.n)\n",
    "    model.optimizer.lr = 0.01\n",
    "    model.fit_generator(batches, batches.n/64, epochs = 30, verbose = 1,\n",
    "                       validation_data = validation_batches, validation_steps = validation_batches.n)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rotation is 60.0%'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 1\n",
    "'rotation is '+  str(20.+((i+1)*20)) + '%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max rotation is: 100.0 degrees\n"
     ]
    }
   ],
   "source": [
    "print('max rotation is: ' + str(20.+(i*20)) + ' degrees')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max rotation is: 20.0 degrees\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/layers/core.py:630: UserWarning: `output_shape` argument not specified for layer lambda_6 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 3, 75, 75)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "18/17 [===============================] - 3s 192ms/step - loss: 0.9377 - acc: 0.5523 - val_loss: 0.6949 - val_acc: 0.4906\n",
      "Epoch 2/2\n",
      "18/17 [===============================] - 3s 172ms/step - loss: 0.7243 - acc: 0.6494 - val_loss: 0.7889 - val_acc: 0.4865\n",
      "Epoch 1/4\n",
      "18/17 [===============================] - 3s 183ms/step - loss: 0.6647 - acc: 0.6786 - val_loss: 0.9096 - val_acc: 0.4865\n",
      "Epoch 2/4\n",
      "18/17 [===============================] - 3s 173ms/step - loss: 0.6141 - acc: 0.7176 - val_loss: 1.0054 - val_acc: 0.4865\n",
      "Epoch 3/4\n",
      "18/17 [===============================] - 3s 173ms/step - loss: 0.6001 - acc: 0.7281 - val_loss: 1.1358 - val_acc: 0.4865\n",
      "Epoch 4/4\n",
      "18/17 [===============================] - 3s 172ms/step - loss: 0.5440 - acc: 0.7556 - val_loss: 1.2677 - val_acc: 0.4865\n",
      "max rotation is: 40.0 degrees\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/layers/core.py:630: UserWarning: `output_shape` argument not specified for layer lambda_7 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 3, 75, 75)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "18/17 [===============================] - 3s 187ms/step - loss: 0.9787 - acc: 0.5360 - val_loss: 0.6983 - val_acc: 0.4927\n",
      "Epoch 2/2\n",
      "18/17 [===============================] - 3s 171ms/step - loss: 0.7964 - acc: 0.6501 - val_loss: 0.8557 - val_acc: 0.4865\n",
      "Epoch 1/4\n",
      "18/17 [===============================] - 3s 180ms/step - loss: 0.7310 - acc: 0.6659 - val_loss: 1.0592 - val_acc: 0.4865\n",
      "Epoch 2/4\n",
      "18/17 [===============================] - 3s 173ms/step - loss: 0.6688 - acc: 0.6942 - val_loss: 1.2575 - val_acc: 0.4865\n",
      "Epoch 3/4\n",
      "18/17 [===============================] - 3s 170ms/step - loss: 0.6363 - acc: 0.6863 - val_loss: 1.5321 - val_acc: 0.4865\n",
      "Epoch 4/4\n",
      "18/17 [===============================] - 3s 171ms/step - loss: 0.5300 - acc: 0.7483 - val_loss: 1.7429 - val_acc: 0.4865\n",
      "max rotation is: 60.0 degrees\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/layers/core.py:630: UserWarning: `output_shape` argument not specified for layer lambda_8 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 3, 75, 75)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "18/17 [===============================] - 3s 193ms/step - loss: 0.8164 - acc: 0.5877 - val_loss: 0.6900 - val_acc: 0.5509\n",
      "Epoch 2/2\n",
      "18/17 [===============================] - 3s 174ms/step - loss: 0.6878 - acc: 0.6778 - val_loss: 0.7680 - val_acc: 0.4865\n",
      "Epoch 1/4\n",
      "18/17 [===============================] - 3s 187ms/step - loss: 0.6621 - acc: 0.6783 - val_loss: 0.8369 - val_acc: 0.4865\n",
      "Epoch 2/4\n",
      "18/17 [===============================] - 3s 175ms/step - loss: 0.6335 - acc: 0.7002 - val_loss: 0.9461 - val_acc: 0.4865\n",
      "Epoch 3/4\n",
      "18/17 [===============================] - 3s 174ms/step - loss: 0.6106 - acc: 0.7118 - val_loss: 1.0958 - val_acc: 0.4865\n",
      "Epoch 4/4\n",
      "18/17 [===============================] - 3s 175ms/step - loss: 0.5283 - acc: 0.7587 - val_loss: 1.2732 - val_acc: 0.4865\n",
      "max rotation is: 80.0 degrees\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/layers/core.py:630: UserWarning: `output_shape` argument not specified for layer lambda_9 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 3, 75, 75)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "18/17 [===============================] - 3s 187ms/step - loss: 0.8768 - acc: 0.5982 - val_loss: 0.7135 - val_acc: 0.4886\n",
      "Epoch 2/2\n",
      "18/17 [===============================] - 3s 169ms/step - loss: 0.7792 - acc: 0.6559 - val_loss: 0.8941 - val_acc: 0.4865\n",
      "Epoch 1/4\n",
      "18/17 [===============================] - 3s 182ms/step - loss: 0.7142 - acc: 0.6782 - val_loss: 1.0288 - val_acc: 0.4865\n",
      "Epoch 2/4\n",
      "18/17 [===============================] - 3s 169ms/step - loss: 0.6840 - acc: 0.6895 - val_loss: 1.1749 - val_acc: 0.4865\n",
      "Epoch 3/4\n",
      "18/17 [===============================] - 3s 173ms/step - loss: 0.6385 - acc: 0.7117 - val_loss: 1.2948 - val_acc: 0.4865\n",
      "Epoch 4/4\n",
      "18/17 [===============================] - 3s 172ms/step - loss: 0.6398 - acc: 0.7188 - val_loss: 1.3629 - val_acc: 0.4865\n",
      "max rotation is: 100.0 degrees\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/layers/core.py:630: UserWarning: `output_shape` argument not specified for layer lambda_10 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 3, 75, 75)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "18/17 [===============================] - 3s 180ms/step - loss: 0.8400 - acc: 0.6101 - val_loss: 0.7128 - val_acc: 0.4865\n",
      "Epoch 2/2\n",
      "18/17 [===============================] - 3s 170ms/step - loss: 0.7080 - acc: 0.6673 - val_loss: 0.7663 - val_acc: 0.4865\n",
      "Epoch 1/4\n",
      "18/17 [===============================] - 3s 183ms/step - loss: 0.6559 - acc: 0.7000 - val_loss: 0.8040 - val_acc: 0.4865\n",
      "Epoch 2/4\n",
      "18/17 [===============================] - 3s 171ms/step - loss: 0.6353 - acc: 0.7090 - val_loss: 0.9083 - val_acc: 0.4865\n",
      "Epoch 3/4\n",
      "18/17 [===============================] - 3s 171ms/step - loss: 0.6165 - acc: 0.7115 - val_loss: 0.9220 - val_acc: 0.4865\n",
      "Epoch 4/4\n",
      "18/17 [===============================] - 3s 172ms/step - loss: 0.5754 - acc: 0.7231 - val_loss: 1.0274 - val_acc: 0.4865\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print('max rotation is: ' + str(20.+(i*20)) + ' degrees')\n",
    "    gen = ImageDataGenerator(rotation_range = 20.+(i*20))\n",
    "    batches = gen.flow(X_train, y_train, batch_size=64, shuffle = True)\n",
    "    model = get_model(batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rotation range of 60% seems to give best increase validation best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zoom is: +/-0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/layers/core.py:630: UserWarning: `output_shape` argument not specified for layer lambda_24 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 3, 75, 75)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-d76cd9f60f96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mgen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzoom_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.05\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-85-e66d1d55f59e>\u001b[0m in \u001b[0;36mget_model\u001b[0;34m(batches)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.00001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     model.fit_generator(batches, batches.n/64, epochs = 2, verbose = 0,\n\u001b[0;32m---> 29\u001b[0;31m                        validation_data = validation_batches, validation_steps = validation_batches.n)\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     model.fit_generator(batches, batches.n/64, epochs = 4, verbose = 0,\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1221\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m                                         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1223\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1994\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1995\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1996\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1997\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdo_validation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1998\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_test_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_make_train_function\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    995\u001b[0m                                                  \u001b[0mupdates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m                                                  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train_function'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 997\u001b[0;31m                                                  **self._function_kwargs)\n\u001b[0m\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_test_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(inputs, outputs, updates, **kwargs)\u001b[0m\n\u001b[1;32m   1230\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Invalid argument \"%s\" passed to K.function with Theano backend'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1232\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, updates, name, **kwargs)\u001b[0m\n\u001b[1;32m   1216\u001b[0m                                         \u001b[0mon_unused_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m                                         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1218\u001b[0;31m                                         **kwargs)\n\u001b[0m\u001b[1;32m   1219\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/compile/function.pyc\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(inputs, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input)\u001b[0m\n\u001b[1;32m    324\u001b[0m                    \u001b[0mon_unused_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m                    \u001b[0mprofile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                    output_keys=output_keys)\n\u001b[0m\u001b[1;32m    327\u001b[0m     \u001b[0;31m# We need to add the flag check_aliased inputs if we have any mutable or\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;31m# borrowed used defined inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/compile/pfunc.pyc\u001b[0m in \u001b[0;36mpfunc\u001b[0;34m(params, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input, output_keys)\u001b[0m\n\u001b[1;32m    484\u001b[0m                          \u001b[0maccept_inplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_inplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m                          \u001b[0mprofile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_unused_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m                          output_keys=output_keys)\n\u001b[0m\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36morig_function\u001b[0;34m(inputs, outputs, mode, accept_inplace, name, profile, on_unused_input, output_keys)\u001b[0m\n\u001b[1;32m   1792\u001b[0m                    \u001b[0mprofile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1793\u001b[0m                    \u001b[0mon_unused_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1794\u001b[0;31m                    \u001b[0moutput_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1795\u001b[0m             defaults)\n\u001b[1;32m   1796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, mode, accept_inplace, function_builder, profile, on_unused_input, fgraph, output_keys)\u001b[0m\n\u001b[1;32m   1472\u001b[0m                         optimizer, inputs, outputs)\n\u001b[1;32m   1473\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1474\u001b[0;31m                     \u001b[0moptimizer_profile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1476\u001b[0m                 \u001b[0mend_optimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/gof/opt.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fgraph)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \"\"\"\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd_requirements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/gof/opt.pyc\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, fgraph, *args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0morig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/gof/opt.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, fgraph)\u001b[0m\n\u001b[1;32m    233\u001b[0m                 \u001b[0mnb_nodes_before\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m                 \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m                 \u001b[0msub_prof\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m                 \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m                 \u001b[0msub_profs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_prof\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/gof/opt.pyc\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, fgraph, *args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0morig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/gof/opt.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, fgraph)\u001b[0m\n\u001b[1;32m    233\u001b[0m                 \u001b[0mnb_nodes_before\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m                 \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m                 \u001b[0msub_prof\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m                 \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m                 \u001b[0msub_profs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_prof\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/gof/opt.pyc\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, fgraph, *args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0morig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/gof/opt.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, fgraph, start_from)\u001b[0m\n\u001b[1;32m   2468\u001b[0m                         \u001b[0mnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchange_tracker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb_imported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2469\u001b[0m                         \u001b[0mt_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2470\u001b[0;31m                         \u001b[0mlopt_change\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2471\u001b[0m                         \u001b[0mtime_opts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlopt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_opt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2472\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlopt_change\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/gof/opt.pyc\u001b[0m in \u001b[0;36mprocess_node\u001b[0;34m(self, fgraph, node, lopt)\u001b[0m\n\u001b[1;32m   2020\u001b[0m             fgraph.replace_all_validate_remove(repl_pairs,\n\u001b[1;32m   2021\u001b[0m                                                \u001b[0mreason\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlopt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2022\u001b[0;31m                                                remove=remove)\n\u001b[0m\u001b[1;32m   2023\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2024\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/gof/toolbox.pyc\u001b[0m in \u001b[0;36mreplace_all_validate_remove\u001b[0;34m(self, fgraph, replacements, remove, reason, warn)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m         \"\"\"\n\u001b[0;32m--> 391\u001b[0;31m         \u001b[0mchk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace_all_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplacements\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodes_removed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mrm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mremove\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/gof/toolbox.pyc\u001b[0m in \u001b[0;36mreplace_all_validate\u001b[0;34m(self, fgraph, replacements, reason, verbose)\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_r\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreplacements\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m                 \u001b[0mfgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreason\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/gof/fg.pyc\u001b[0m in \u001b[0;36mreplace\u001b[0;34m(self, r, new_r, reason, verbose)\u001b[0m\n\u001b[1;32m    507\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# copy the client list for iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'output'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchange_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0;31m# sometimes the following is triggered.  If you understand why, please explain to James.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/gof/fg.pyc\u001b[0m in \u001b[0;36mchange_input\u001b[0;34m(self, node, i, new_r, reason)\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__import_r__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__add_client__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__remove_client__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/gof/fg.pyc\u001b[0m in \u001b[0;36m__import_r__\u001b[0;34m(self, variable, reason)\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0;31m# Imports the owners of the variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mowner\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mowner\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_nodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__import__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mowner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m         elif (variable.owner is None and\n\u001b[1;32m    353\u001b[0m                 \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConstant\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/gof/fg.pyc\u001b[0m in \u001b[0;36m__import__\u001b[0;34m(self, apply_node, check, reason)\u001b[0m\n\u001b[1;32m    413\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__add_client__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'on_import'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[0;31m# change input #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/gof/fg.pyc\u001b[0m in \u001b[0;36mexecute_callbacks\u001b[0;34m(self, name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    587\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0mtf0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m             \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_callbacks_times\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtf0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_callbacks_time\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/tensor/opt.pyc\u001b[0m in \u001b[0;36mon_import\u001b[0;34m(self, fgraph, node, reason)\u001b[0m\n\u001b[1;32m   1316\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_r\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1318\u001b[0;31m         \u001b[0mo_shapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_node_infer_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0;31m# this is packed information\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/tensor/opt.pyc\u001b[0m in \u001b[0;36mget_node_infer_shape\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    944\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m             o_shapes = shape_infer(node,\n\u001b[0;32m--> 946\u001b[0;31m                                    [self.shape_of[r] for r in node.inputs])\n\u001b[0m\u001b[1;32m    947\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mShapeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m             o_shapes = self.default_infer_shape(node, [self.shape_of[r] for\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/tensor/opt.pyc\u001b[0m in \u001b[0;36mdefault_infer_shape\u001b[0;34m(self, node, i_shapes)\u001b[0m\n\u001b[1;32m   1042\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m                 \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m                 \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/tensor/opt.pyc\u001b[0m in \u001b[0;36mshape_tuple\u001b[0;34m(self, r)\u001b[0m\n\u001b[1;32m   1029\u001b[0m             \u001b[0;31m# This happen for NoneConst.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1031\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_ir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdefault_infer_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/tensor/opt.pyc\u001b[0m in \u001b[0;36mshape_ir\u001b[0;34m(self, i, r)\u001b[0m\n\u001b[1;32m   1017\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m             \u001b[0;31m# Do not call make_node for test_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1019\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mShape_i\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1020\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m                 \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_scalar_constant_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \"\"\"\n\u001b[1;32m    614\u001b[0m         \u001b[0mreturn_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'return_list'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m         \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_test_value\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'off'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/compile/ops.pyc\u001b[0m in \u001b[0;36mmake_node\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    357\u001b[0m             raise TypeError('x has too few dimensions for Shape_i',\n\u001b[1;32m    358\u001b[0m                             (x, self.i))\n\u001b[0;32m--> 359\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mperform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/gof/graph.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, op, inputs, outputs)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;31m# filter outputs to make sure each element is a Variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mowner\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print('zoom is: +/-' + str(0.05 + (i*0.05)))\n",
    "    gen = ImageDataGenerator(zoom_range = (0.05 + i*0.05))\n",
    "    batches = gen.flow(X_train, y_train, batch_size=64, shuffle = True)\n",
    "    model = get_model(batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Less zoom is best (+/- 5%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## having weird problem where validation accuracy hits local minimum - going to try model with some dropout\n",
    "\n",
    "solution - needed more epochs at a really low learning rate \n",
    "\n",
    "Further testing shows that vertical flip doesn't help but horizontal flip does (.59 accuracy vs .55)\n",
    "\n",
    "Remove first dropout = 65% accuracy\n",
    "Remove second dropout = 63% accuracy\n",
    "Remove last dropout = 70% accuracy\n",
    "\n",
    "Remove first and last dropout = 75% accuracy\n",
    "No dropout = 74% accuracy\n",
    "\n",
    "only second dropout\n",
    "Adding FC dropout (10%) = 70% acc\n",
    "\n",
    "\"                \"(20%) = 73% acc\n",
    "\n",
    "\"                \"(30%) = 65% acc\n",
    "\n",
    "second dropout at 20%, FC dropout 20% = 62% accuracy\n",
    "\n",
    "Peak accuracy with 40 epochs on last lr = 80% (very little overfitting - !!)\n",
    "\n",
    "10 epochs at .1 lr and 10 epochs at .01 lr = 75% accuracy\n",
    "\n",
    "Adding another fully connected layer with 256 outputs = 77% accuracy \n",
    "\n",
    "Adding dropout between fully connected layers = 77% accuracy\n",
    "\n",
    "Removing FC dropout = 77% accuracy\n",
    "\n",
    "changing second FC layer to 128 outputs = 78% accuracy\n",
    "\n",
    "adding 10% dropout between fully connected layers = 72% accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gen = ImageDataGenerator(rotation_range = 60.,\n",
    "                        zoom_range = 0.05,\n",
    "                        horizontal_flip = True,\n",
    "                        vertical_flip = False)\n",
    "batches = gen.flow(X_train, y_train, batch_size=64, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/layers/core.py:630: UserWarning: `output_shape` argument not specified for layer lambda_51 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 3, 75, 75)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "18/17 [===============================] - 3s 193ms/step - loss: 0.4944 - acc: 0.7724 - val_loss: 1.5386 - val_acc: 0.4865\n",
      "Epoch 2/30\n",
      "18/17 [===============================] - 3s 180ms/step - loss: 0.4789 - acc: 0.7726 - val_loss: 1.5030 - val_acc: 0.4865\n",
      "Epoch 3/30\n",
      "18/17 [===============================] - 3s 180ms/step - loss: 0.4950 - acc: 0.7572 - val_loss: 1.5120 - val_acc: 0.4865\n",
      "Epoch 4/30\n",
      "18/17 [===============================] - 3s 181ms/step - loss: 0.4859 - acc: 0.7661 - val_loss: 1.5046 - val_acc: 0.4865\n",
      "Epoch 5/30\n",
      "18/17 [===============================] - 3s 180ms/step - loss: 0.4845 - acc: 0.7637 - val_loss: 1.4628 - val_acc: 0.4865\n",
      "Epoch 6/30\n",
      "18/17 [===============================] - 3s 181ms/step - loss: 0.4552 - acc: 0.7875 - val_loss: 1.3796 - val_acc: 0.4948\n",
      "Epoch 7/30\n",
      "18/17 [===============================] - 3s 181ms/step - loss: 0.4761 - acc: 0.7727 - val_loss: 1.3450 - val_acc: 0.5052\n",
      "Epoch 8/30\n",
      "18/17 [===============================] - 3s 181ms/step - loss: 0.4612 - acc: 0.7824 - val_loss: 1.2612 - val_acc: 0.5156\n",
      "Epoch 9/30\n",
      "18/17 [===============================] - 3s 182ms/step - loss: 0.4726 - acc: 0.7793 - val_loss: 1.1845 - val_acc: 0.5343\n",
      "Epoch 10/30\n",
      "18/17 [===============================] - 3s 181ms/step - loss: 0.4583 - acc: 0.7623 - val_loss: 1.1177 - val_acc: 0.5468\n",
      "Epoch 11/30\n",
      "18/17 [===============================] - 3s 181ms/step - loss: 0.4202 - acc: 0.8054 - val_loss: 1.0749 - val_acc: 0.5572\n",
      "Epoch 12/30\n",
      "18/17 [===============================] - 3s 182ms/step - loss: 0.4478 - acc: 0.7885 - val_loss: 0.9782 - val_acc: 0.5738\n",
      "Epoch 13/30\n",
      "18/17 [===============================] - 3s 182ms/step - loss: 0.4225 - acc: 0.8056 - val_loss: 0.9001 - val_acc: 0.5925\n",
      "Epoch 14/30\n",
      "18/17 [===============================] - 3s 181ms/step - loss: 0.4282 - acc: 0.7947 - val_loss: 0.8581 - val_acc: 0.6071\n",
      "Epoch 15/30\n",
      "18/17 [===============================] - 3s 182ms/step - loss: 0.4228 - acc: 0.8000 - val_loss: 0.8365 - val_acc: 0.6071\n",
      "Epoch 16/30\n",
      "18/17 [===============================] - 3s 180ms/step - loss: 0.4050 - acc: 0.8083 - val_loss: 0.7879 - val_acc: 0.6279\n",
      "Epoch 17/30\n",
      "18/17 [===============================] - 3s 181ms/step - loss: 0.4174 - acc: 0.8083 - val_loss: 0.7372 - val_acc: 0.6466\n",
      "Epoch 18/30\n",
      "18/17 [===============================] - 3s 182ms/step - loss: 0.4152 - acc: 0.7850 - val_loss: 0.7090 - val_acc: 0.6590\n",
      "Epoch 19/30\n",
      "18/17 [===============================] - 3s 181ms/step - loss: 0.4305 - acc: 0.7840 - val_loss: 0.6762 - val_acc: 0.6653\n",
      "Epoch 20/30\n",
      "18/17 [===============================] - 3s 181ms/step - loss: 0.4098 - acc: 0.8081 - val_loss: 0.6402 - val_acc: 0.6798\n",
      "Epoch 21/30\n",
      "18/17 [===============================] - 3s 182ms/step - loss: 0.4305 - acc: 0.7904 - val_loss: 0.6402 - val_acc: 0.6840\n",
      "Epoch 22/30\n",
      "18/17 [===============================] - 3s 181ms/step - loss: 0.4197 - acc: 0.8005 - val_loss: 0.6179 - val_acc: 0.6923\n",
      "Epoch 23/30\n",
      "18/17 [===============================] - 3s 180ms/step - loss: 0.4014 - acc: 0.8101 - val_loss: 0.5899 - val_acc: 0.7110\n",
      "Epoch 24/30\n",
      "18/17 [===============================] - 3s 182ms/step - loss: 0.4115 - acc: 0.8135 - val_loss: 0.5779 - val_acc: 0.7110\n",
      "Epoch 25/30\n",
      "18/17 [===============================] - 3s 181ms/step - loss: 0.3883 - acc: 0.8219 - val_loss: 0.5669 - val_acc: 0.7152\n",
      "Epoch 26/30\n",
      "18/17 [===============================] - 3s 181ms/step - loss: 0.4053 - acc: 0.8194 - val_loss: 0.5573 - val_acc: 0.7256\n",
      "Epoch 27/30\n",
      "18/17 [===============================] - 3s 182ms/step - loss: 0.3955 - acc: 0.8089 - val_loss: 0.5523 - val_acc: 0.7256\n",
      "Epoch 28/30\n",
      "18/17 [===============================] - 3s 181ms/step - loss: 0.4064 - acc: 0.7944 - val_loss: 0.5415 - val_acc: 0.7235\n",
      "Epoch 29/30\n",
      "18/17 [===============================] - 3s 182ms/step - loss: 0.3786 - acc: 0.8236 - val_loss: 0.5275 - val_acc: 0.7297\n",
      "Epoch 30/30\n",
      "18/17 [===============================] - 3s 181ms/step - loss: 0.3648 - acc: 0.8344 - val_loss: 0.5234 - val_acc: 0.7360\n"
     ]
    }
   ],
   "source": [
    "model = get_model(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "18/17 [===============================] - 4s 203ms/step - loss: 0.3584 - acc: 0.8346 - val_loss: 0.4751 - val_acc: 0.7713\n",
      "Epoch 2/10\n",
      "18/17 [===============================] - 3s 184ms/step - loss: 0.3670 - acc: 0.8354 - val_loss: 0.4791 - val_acc: 0.7630\n",
      "Epoch 3/10\n",
      "18/17 [===============================] - 3s 184ms/step - loss: 0.3533 - acc: 0.8399 - val_loss: 0.4597 - val_acc: 0.7796\n",
      "Epoch 4/10\n",
      "18/17 [===============================] - 3s 186ms/step - loss: 0.3612 - acc: 0.8432 - val_loss: 0.4628 - val_acc: 0.7734\n",
      "Epoch 5/10\n",
      "18/17 [===============================] - 3s 185ms/step - loss: 0.3676 - acc: 0.8400 - val_loss: 0.4635 - val_acc: 0.7713\n",
      "Epoch 6/10\n",
      "18/17 [===============================] - 3s 184ms/step - loss: 0.3423 - acc: 0.8376 - val_loss: 0.4514 - val_acc: 0.7775\n",
      "Epoch 7/10\n",
      "18/17 [===============================] - 3s 185ms/step - loss: 0.3658 - acc: 0.8347 - val_loss: 0.4477 - val_acc: 0.7796\n",
      "Epoch 8/10\n",
      "18/17 [===============================] - 3s 185ms/step - loss: 0.3450 - acc: 0.8444 - val_loss: 0.4471 - val_acc: 0.7775\n",
      "Epoch 9/10\n",
      "18/17 [===============================] - 3s 183ms/step - loss: 0.3263 - acc: 0.8556 - val_loss: 0.4342 - val_acc: 0.7838\n",
      "Epoch 10/10\n",
      "18/17 [===============================] - 3s 185ms/step - loss: 0.3367 - acc: 0.8472 - val_loss: 0.4347 - val_acc: 0.7817\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9757bac950>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr = 0.001\n",
    "model.fit_generator(batches, batches.n/64, epochs = 10, verbose = 1,\n",
    "                       validation_data = validation_batches, validation_steps = validation_batches.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_46 (Lambda)           (None, 3, 75, 75)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_271 (Conv2D)          (None, 32, 73, 73)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_226 (Bat (None, 32, 73, 73)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_272 (Conv2D)          (None, 32, 71, 71)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_136 (MaxPoolin (None, 32, 35, 35)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_273 (Conv2D)          (None, 64, 33, 33)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_227 (Bat (None, 64, 33, 33)        256       \n",
      "_________________________________________________________________\n",
      "dropout_83 (Dropout)         (None, 64, 33, 33)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_274 (Conv2D)          (None, 64, 31, 31)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_137 (MaxPoolin (None, 64, 15, 15)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_275 (Conv2D)          (None, 128, 13, 13)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_228 (Bat (None, 128, 13, 13)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_276 (Conv2D)          (None, 128, 11, 11)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_138 (MaxPoolin (None, 128, 5, 5)         0         \n",
      "_________________________________________________________________\n",
      "flatten_46 (Flatten)         (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_229 (Bat (None, 3200)              12800     \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 512)               1638912   \n",
      "_________________________________________________________________\n",
      "batch_normalization_230 (Bat (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_84 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 1,942,690\n",
      "Trainable params: 1,934,818\n",
      "Non-trainable params: 7,872\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. increase size of dataset for training\n",
    "\n",
    "Using fit instead of fit_generator now so I need to get the features of the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_feat = model.predict_generator(validation_batches, validation_batches.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aug_feat = model.predict_generator(batches, batches.n*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aug_labels = ([y_train]*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dn.fit(aug_feat, aug_labels, batch_size = 64, epochs = 1, validation_data = (val_feat, y_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NB: Run model in such a way to save weights to make the following ensembling go faster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Skip to ensemble model, these calculations are no longer needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dn.fit_generator(batches, batches.n/64, epochs = 1, \n",
    "                validation_data = validation_batches, validation_steps = validation_batches.n/64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dn.optimizer.lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dn.fit_generator(batches, batches.n/64, epochs = 5, \n",
    "                validation_data = validation_batches, validation_steps = validation_batches.n/64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dn.optimizer.lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dn.fit_generator(batches, batches.n/64, epochs = 15, \n",
    "                validation_data = validation_batches, validation_steps = validation_batches.n/64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble model\n",
    "\n",
    "Todo: use learnings from previous section to update the ensemble model to generate better predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ensemble() :\n",
    "    model = get_cnn_dropout_model()\n",
    "    model.fit_generator(batches, batches.n/64, epochs = 1, verbose = 0, \n",
    "                validation_data = validation_batches, validation_steps = validation_batches.n/64)\n",
    "    model.optimizer.lr = 0.1\n",
    "    model.fit_generator(batches, batches.n/64, epochs = 4,  verbose = 0, \n",
    "                validation_data = validation_batches, validation_steps = validation_batches.n/64)\n",
    "    model.optimizer.lr = 0.01\n",
    "    model.fit_generator(batches, batches.n/64, epochs = 12,  verbose = 0, \n",
    "                validation_data = validation_batches, validation_steps = validation_batches.n/64)\n",
    "    model.optimizer.lr = 0.001\n",
    "    model.fit_generator(batches, batches.n/64, epochs = 16,  verbose = 1, \n",
    "                validation_data = validation_batches, validation_steps = validation_batches.n/64)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/layers/core.py:630: UserWarning: `output_shape` argument not specified for layer lambda_2 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 3, 75, 75)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "18/17 [===============================] - 4s 200ms/step - loss: 0.3331 - acc: 0.8597 - val_loss: 0.9814 - val_acc: 0.6237\n",
      "Epoch 2/16\n",
      "18/17 [===============================] - 4s 207ms/step - loss: 0.2953 - acc: 0.8657 - val_loss: 1.6420 - val_acc: 0.5426\n",
      "Epoch 3/16\n",
      "18/17 [===============================] - 3s 191ms/step - loss: 0.3068 - acc: 0.8713 - val_loss: 1.1100 - val_acc: 0.6362\n",
      "Epoch 4/16\n",
      "18/17 [===============================] - 4s 209ms/step - loss: 0.2822 - acc: 0.8800 - val_loss: 1.4465 - val_acc: 0.5842\n",
      "Epoch 5/16\n",
      "18/17 [===============================] - 4s 230ms/step - loss: 0.2991 - acc: 0.8657 - val_loss: 0.7199 - val_acc: 0.6819\n",
      "Epoch 6/16\n",
      "18/17 [===============================] - 4s 224ms/step - loss: 0.3183 - acc: 0.8688 - val_loss: 0.7197 - val_acc: 0.6778\n",
      "Epoch 7/16\n",
      "18/17 [===============================] - 4s 196ms/step - loss: 0.2887 - acc: 0.8745 - val_loss: 0.5286 - val_acc: 0.7921\n",
      "Epoch 8/16\n",
      "18/17 [===============================] - 3s 186ms/step - loss: 0.2794 - acc: 0.8771 - val_loss: 2.0063 - val_acc: 0.5364\n",
      "Epoch 9/16\n",
      "18/17 [===============================] - 3s 192ms/step - loss: 0.3161 - acc: 0.8648 - val_loss: 1.0441 - val_acc: 0.6861\n",
      "Epoch 10/16\n",
      "18/17 [===============================] - 4s 208ms/step - loss: 0.2821 - acc: 0.8763 - val_loss: 0.3312 - val_acc: 0.8441\n",
      "Epoch 11/16\n",
      "18/17 [===============================] - 3s 191ms/step - loss: 0.2607 - acc: 0.8811 - val_loss: 0.7666 - val_acc: 0.7193\n",
      "Epoch 12/16\n",
      "18/17 [===============================] - 4s 197ms/step - loss: 0.2839 - acc: 0.8774 - val_loss: 0.7970 - val_acc: 0.7360\n",
      "Epoch 13/16\n",
      "18/17 [===============================] - 3s 185ms/step - loss: 0.2493 - acc: 0.8951 - val_loss: 0.3271 - val_acc: 0.8545\n",
      "Epoch 14/16\n",
      "18/17 [===============================] - 3s 191ms/step - loss: 0.2824 - acc: 0.8742 - val_loss: 0.3636 - val_acc: 0.8607\n",
      "Epoch 15/16\n",
      "18/17 [===============================] - 4s 219ms/step - loss: 0.2657 - acc: 0.8867 - val_loss: 0.4640 - val_acc: 0.8025\n",
      "Epoch 16/16\n",
      "18/17 [===============================] - 4s 202ms/step - loss: 0.2617 - acc: 0.8866 - val_loss: 0.3086 - val_acc: 0.8649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/layers/core.py:630: UserWarning: `output_shape` argument not specified for layer lambda_3 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 3, 75, 75)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "18/17 [===============================] - 4s 201ms/step - loss: 0.3213 - acc: 0.8658 - val_loss: 2.1599 - val_acc: 0.5426\n",
      "Epoch 2/16\n",
      "18/17 [===============================] - 4s 196ms/step - loss: 0.2929 - acc: 0.8678 - val_loss: 0.8075 - val_acc: 0.6632\n",
      "Epoch 3/16\n",
      "18/17 [===============================] - 4s 196ms/step - loss: 0.2842 - acc: 0.8856 - val_loss: 1.4938 - val_acc: 0.5863\n",
      "Epoch 4/16\n",
      "18/17 [===============================] - 3s 190ms/step - loss: 0.2903 - acc: 0.8703 - val_loss: 1.1837 - val_acc: 0.6507\n",
      "Epoch 5/16\n",
      "18/17 [===============================] - 4s 197ms/step - loss: 0.2872 - acc: 0.8750 - val_loss: 0.3966 - val_acc: 0.8420\n",
      "Epoch 6/16\n",
      "18/17 [===============================] - 3s 191ms/step - loss: 0.2822 - acc: 0.8691 - val_loss: 0.8305 - val_acc: 0.6819\n",
      "Epoch 7/16\n",
      "18/17 [===============================] - 3s 192ms/step - loss: 0.2792 - acc: 0.8852 - val_loss: 0.4297 - val_acc: 0.7921\n",
      "Epoch 8/16\n",
      "18/17 [===============================] - 4s 196ms/step - loss: 0.2671 - acc: 0.8783 - val_loss: 0.5668 - val_acc: 0.7484\n",
      "Epoch 9/16\n",
      "18/17 [===============================] - 3s 191ms/step - loss: 0.2402 - acc: 0.9042 - val_loss: 0.3946 - val_acc: 0.8462\n",
      "Epoch 10/16\n",
      "18/17 [===============================] - 4s 197ms/step - loss: 0.3079 - acc: 0.8629 - val_loss: 0.3241 - val_acc: 0.8607\n",
      "Epoch 11/16\n",
      "18/17 [===============================] - 3s 186ms/step - loss: 0.3442 - acc: 0.8507 - val_loss: 0.7592 - val_acc: 0.7048\n",
      "Epoch 12/16\n",
      "18/17 [===============================] - 3s 191ms/step - loss: 0.2846 - acc: 0.8772 - val_loss: 0.4399 - val_acc: 0.8358\n",
      "Epoch 13/16\n",
      "18/17 [===============================] - 4s 202ms/step - loss: 0.2571 - acc: 0.8890 - val_loss: 0.2867 - val_acc: 0.8794\n",
      "Epoch 14/16\n",
      "18/17 [===============================] - 4s 208ms/step - loss: 0.2867 - acc: 0.8690 - val_loss: 0.3275 - val_acc: 0.8669\n",
      "Epoch 15/16\n",
      "18/17 [===============================] - 3s 190ms/step - loss: 0.2958 - acc: 0.8716 - val_loss: 0.3550 - val_acc: 0.8482\n",
      "Epoch 16/16\n",
      "18/17 [===============================] - 3s 191ms/step - loss: 0.3010 - acc: 0.8737 - val_loss: 0.3636 - val_acc: 0.8462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/layers/core.py:630: UserWarning: `output_shape` argument not specified for layer lambda_4 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 3, 75, 75)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "18/17 [===============================] - 4s 203ms/step - loss: 0.2954 - acc: 0.8676 - val_loss: 0.6361 - val_acc: 0.7235\n",
      "Epoch 2/16\n",
      "18/17 [===============================] - 3s 192ms/step - loss: 0.3069 - acc: 0.8631 - val_loss: 1.1442 - val_acc: 0.6029\n",
      "Epoch 3/16\n",
      "18/17 [===============================] - 4s 198ms/step - loss: 0.3108 - acc: 0.8604 - val_loss: 0.6989 - val_acc: 0.7110\n",
      "Epoch 4/16\n",
      "18/17 [===============================] - 4s 202ms/step - loss: 0.3054 - acc: 0.8645 - val_loss: 0.9703 - val_acc: 0.6528\n",
      "Epoch 5/16\n",
      "18/17 [===============================] - 4s 196ms/step - loss: 0.3397 - acc: 0.8548 - val_loss: 0.8540 - val_acc: 0.6445\n",
      "Epoch 6/16\n",
      "18/17 [===============================] - 4s 204ms/step - loss: 0.2810 - acc: 0.8756 - val_loss: 0.4427 - val_acc: 0.7983\n",
      "Epoch 7/16\n",
      "18/17 [===============================] - 4s 203ms/step - loss: 0.3019 - acc: 0.8787 - val_loss: 0.3351 - val_acc: 0.8711\n",
      "Epoch 8/16\n",
      "18/17 [===============================] - 3s 191ms/step - loss: 0.3091 - acc: 0.8669 - val_loss: 0.4443 - val_acc: 0.7921\n",
      "Epoch 9/16\n",
      "18/17 [===============================] - 4s 202ms/step - loss: 0.2877 - acc: 0.8705 - val_loss: 0.9243 - val_acc: 0.6757\n",
      "Epoch 10/16\n",
      "18/17 [===============================] - 3s 191ms/step - loss: 0.2873 - acc: 0.8796 - val_loss: 0.4597 - val_acc: 0.8212\n",
      "Epoch 11/16\n",
      "18/17 [===============================] - 4s 196ms/step - loss: 0.2920 - acc: 0.8591 - val_loss: 0.3189 - val_acc: 0.8690\n",
      "Epoch 12/16\n",
      "18/17 [===============================] - 3s 191ms/step - loss: 0.2868 - acc: 0.8846 - val_loss: 0.4781 - val_acc: 0.7796\n",
      "Epoch 13/16\n",
      "18/17 [===============================] - 4s 233ms/step - loss: 0.2646 - acc: 0.8778 - val_loss: 0.2899 - val_acc: 0.8711\n",
      "Epoch 14/16\n",
      "18/17 [===============================] - 3s 191ms/step - loss: 0.2995 - acc: 0.8760 - val_loss: 0.3168 - val_acc: 0.8524\n",
      "Epoch 15/16\n",
      "18/17 [===============================] - 4s 197ms/step - loss: 0.2788 - acc: 0.8741 - val_loss: 0.6509 - val_acc: 0.7089\n",
      "Epoch 16/16\n",
      "18/17 [===============================] - 4s 197ms/step - loss: 0.2581 - acc: 0.8923 - val_loss: 0.2886 - val_acc: 0.8669\n"
     ]
    }
   ],
   "source": [
    "models = [get_ensemble() for i in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_path = path+'models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i,m in enumerate(models):\n",
    "    m.save_weights(model_path + 'cnn_statoil_' + str(i) + '.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "481/481 [==============================] - 0s 983us/step\n",
      "481/481 [==============================] - 0s 784us/step\n",
      "481/481 [==============================] - 0s 716us/step\n"
     ]
    }
   ],
   "source": [
    "evals = np.array([m.evaluate(X_validate, y_validate, batch_size=256) for m in models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.31128727,  0.86555786])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evals.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_preds = np.stack([m.predict(X_test, batch_size = 256) for m in models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 8424, 2)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_preds = all_preds.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9.87748384e-01,   1.22515941e-02],\n",
       "       [  2.95811206e-01,   7.04188824e-01],\n",
       "       [  9.99622107e-01,   3.77853168e-04],\n",
       "       [  1.49961412e-02,   9.85003889e-01],\n",
       "       [  1.97269008e-01,   8.02730978e-01]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.22515941e-02,   7.04188824e-01,   3.77853168e-04, ...,\n",
       "         8.63429084e-02,   9.87904549e-01,   9.51587975e-01], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_preds[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.31043216,  0.86070687],\n",
       "       [ 0.3627157 ,  0.84823284],\n",
       "       [ 0.26071394,  0.88773388]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_validate[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>band_1</th>\n",
       "      <th>band_2</th>\n",
       "      <th>id</th>\n",
       "      <th>inc_angle</th>\n",
       "      <th>is_iceberg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[-21.397552, -19.753859, -23.426783, -24.65221...</td>\n",
       "      <td>[-26.72291, -27.418192, -27.787899, -25.774536...</td>\n",
       "      <td>3aac67cd</td>\n",
       "      <td>44.6240</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>[-25.098461, -25.098461, -24.320147, -21.05014...</td>\n",
       "      <td>[-29.62639, -29.62639, -28.757122, -29.180954,...</td>\n",
       "      <td>b7519a52</td>\n",
       "      <td>42.5590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>[-21.582905, -15.472338, -16.417433, -16.72227...</td>\n",
       "      <td>[-25.104729, -24.326412, -28.763432, -32.92899...</td>\n",
       "      <td>204941f0</td>\n",
       "      <td>42.4664</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>[-13.271194, -12.898959, -14.867657, -16.54327...</td>\n",
       "      <td>[-22.941357, -23.540695, -24.41008, -24.879778...</td>\n",
       "      <td>f9209504</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>[-13.523142, -10.304675, -11.433078, -9.585804...</td>\n",
       "      <td>[-21.386665, -21.076504, -20.776958, -22.21468...</td>\n",
       "      <td>204afe46</td>\n",
       "      <td>32.8010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 band_1  \\\n",
       "10    [-21.397552, -19.753859, -23.426783, -24.65221...   \n",
       "1003  [-25.098461, -25.098461, -24.320147, -21.05014...   \n",
       "1006  [-21.582905, -15.472338, -16.417433, -16.72227...   \n",
       "101   [-13.271194, -12.898959, -14.867657, -16.54327...   \n",
       "1012  [-13.523142, -10.304675, -11.433078, -9.585804...   \n",
       "\n",
       "                                                 band_2        id  inc_angle  \\\n",
       "10    [-26.72291, -27.418192, -27.787899, -25.774536...  3aac67cd    44.6240   \n",
       "1003  [-29.62639, -29.62639, -28.757122, -29.180954,...  b7519a52    42.5590   \n",
       "1006  [-25.104729, -24.326412, -28.763432, -32.92899...  204941f0    42.4664   \n",
       "101   [-22.941357, -23.540695, -24.41008, -24.879778...  f9209504        NaN   \n",
       "1012  [-21.386665, -21.076504, -20.776958, -22.21468...  204afe46    32.8010   \n",
       "\n",
       "      is_iceberg  \n",
       "10             1  \n",
       "1003           1  \n",
       "1006           0  \n",
       "101            0  \n",
       "1012           1  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_batch[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['id']=test_batch['id']\n",
    "submission['is_iceberg']=avg_preds[:,1].clip(0.025, 0.975)\n",
    "submission.to_csv(path+'submission17124.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.025     ,  0.70418882,  0.025     , ...,  0.08634291,\n",
       "        0.97500002,  0.95158798], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_preds[:,1].clip(0.025, 0.975)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/courses/deeplearning1/nbs/statoil-nb'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "import os, sys\n",
    "submit_path = os.getcwd()\n",
    "submit_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submit_path = submit_path+'/../data/statoil'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='/home/ubuntu/courses/deeplearning1/nbs/statoil-nb/../data/statoil/submission17124.csv' target='_blank'>/home/ubuntu/courses/deeplearning1/nbs/statoil-nb/../data/statoil/submission17124.csv</a><br>"
      ],
      "text/plain": [
       "/home/ubuntu/courses/deeplearning1/nbs/data/statoil/submission17124.csv"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FileLink(submit_path+'/submission17124.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
